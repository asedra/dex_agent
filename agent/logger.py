#!/usr/bin/env python3
"""
DexAgents Logger - Advanced logging system with rotation and filtering
"""

import logging
import logging.handlers
import os
import sys
import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import threading
import queue
import traceback

class Logger:
    def __init__(self, name: str = "DexAgents", log_dir: str = "logs"):
        self.name = name
        self.log_dir = log_dir
        self.log_file = os.path.join(log_dir, "dexagents.log")
        self.error_log_file = os.path.join(log_dir, "dexagents_errors.log")
        
        # Configuration
        self.max_log_size_mb = 10
        self.max_log_files = 5
        self.log_level = logging.INFO
        self.console_output = True
        
        # In-memory log storage for GUI
        self.memory_logs = []
        self.max_memory_logs = 1000
        self.memory_lock = threading.Lock()
        
        # Async logging queue
        self.log_queue = queue.Queue(maxsize=10000)
        self.queue_thread = None
        self.queue_running = False
        
        # Performance metrics
        self.log_stats = {
            'total_logs': 0,
            'debug_logs': 0,
            'info_logs': 0,
            'warning_logs': 0,\n            'error_logs': 0,\n            'critical_logs': 0,\n            'start_time': datetime.now()\n        }\n        \n        # Setup logging\n        self._setup_logging()\n        \n        # Start background thread\n        self._start_queue_processor()\n    \n    def _setup_logging(self):\n        \"\"\"Setup logging configuration\"\"\"\n        # Create log directory\n        os.makedirs(self.log_dir, exist_ok=True)\n        \n        # Create logger\n        self.logger = logging.getLogger(self.name)\n        self.logger.setLevel(self.log_level)\n        \n        # Clear existing handlers\n        self.logger.handlers.clear()\n        \n        # Create formatters\n        detailed_formatter = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(funcName)s() - %(message)s',\n            datefmt='%Y-%m-%d %H:%M:%S'\n        )\n        \n        simple_formatter = logging.Formatter(\n            '%(asctime)s - %(levelname)s - %(message)s',\n            datefmt='%H:%M:%S'\n        )\n        \n        # File handler with rotation\n        try:\n            file_handler = logging.handlers.RotatingFileHandler(\n                self.log_file,\n                maxBytes=self.max_log_size_mb * 1024 * 1024,\n                backupCount=self.max_log_files,\n                encoding='utf-8'\n            )\n            file_handler.setLevel(logging.DEBUG)\n            file_handler.setFormatter(detailed_formatter)\n            self.logger.addHandler(file_handler)\n        except Exception as e:\n            print(f\"Failed to setup file logging: {e}\")\n        \n        # Error file handler\n        try:\n            error_handler = logging.handlers.RotatingFileHandler(\n                self.error_log_file,\n                maxBytes=self.max_log_size_mb * 1024 * 1024,\n                backupCount=self.max_log_files,\n                encoding='utf-8'\n            )\n            error_handler.setLevel(logging.WARNING)\n            error_handler.setFormatter(detailed_formatter)\n            self.logger.addHandler(error_handler)\n        except Exception as e:\n            print(f\"Failed to setup error file logging: {e}\")\n        \n        # Console handler\n        if self.console_output:\n            console_handler = logging.StreamHandler(sys.stdout)\n            console_handler.setLevel(self.log_level)\n            console_handler.setFormatter(simple_formatter)\n            self.logger.addHandler(console_handler)\n        \n        # Memory handler for GUI\n        memory_handler = MemoryHandler(self)\n        memory_handler.setLevel(logging.DEBUG)\n        memory_handler.setFormatter(detailed_formatter)\n        self.logger.addHandler(memory_handler)\n    \n    def _start_queue_processor(self):\n        \"\"\"Start background thread for async logging\"\"\"\n        if self.queue_running:\n            return\n        \n        self.queue_running = True\n        \n        def process_queue():\n            while self.queue_running:\n                try:\n                    # Get log record from queue with timeout\n                    record = self.log_queue.get(timeout=1.0)\n                    \n                    if record is None:  # Shutdown signal\n                        break\n                    \n                    # Process the log record\n                    self.logger.handle(record)\n                    \n                except queue.Empty:\n                    continue\n                except Exception as e:\n                    # Log errors in queue processing to stderr\n                    print(f\"Error in log queue processor: {e}\", file=sys.stderr)\n        \n        self.queue_thread = threading.Thread(target=process_queue, daemon=True)\n        self.queue_thread.start()\n    \n    def _stop_queue_processor(self):\n        \"\"\"Stop background queue processor\"\"\"\n        if not self.queue_running:\n            return\n        \n        self.queue_running = False\n        \n        # Send shutdown signal\n        try:\n            self.log_queue.put(None, timeout=1.0)\n        except queue.Full:\n            pass\n        \n        # Wait for thread to finish\n        if self.queue_thread and self.queue_thread.is_alive():\n            self.queue_thread.join(timeout=5.0)\n    \n    def _log_async(self, level: int, message: str, *args, **kwargs):\n        \"\"\"Log message asynchronously\"\"\"\n        try:\n            # Create log record\n            record = self.logger.makeRecord(\n                self.logger.name, level, \"<unknown>\", 0, message, args, None\n            )\n            \n            # Add to queue\n            self.log_queue.put(record, block=False)\n            \n        except queue.Full:\n            # If queue is full, log synchronously as fallback\n            self._log_sync(level, message, *args, **kwargs)\n        except Exception as e:\n            print(f\"Error in async logging: {e}\", file=sys.stderr)\n    \n    def _log_sync(self, level: int, message: str, *args, **kwargs):\n        \"\"\"Log message synchronously\"\"\"\n        self.logger.log(level, message, *args, **kwargs)\n    \n    def _update_stats(self, level: int):\n        \"\"\"Update logging statistics\"\"\"\n        self.log_stats['total_logs'] += 1\n        \n        if level == logging.DEBUG:\n            self.log_stats['debug_logs'] += 1\n        elif level == logging.INFO:\n            self.log_stats['info_logs'] += 1\n        elif level == logging.WARNING:\n            self.log_stats['warning_logs'] += 1\n        elif level == logging.ERROR:\n            self.log_stats['error_logs'] += 1\n        elif level == logging.CRITICAL:\n            self.log_stats['critical_logs'] += 1\n    \n    # Public logging methods\n    def debug(self, message: str, *args, **kwargs):\n        \"\"\"Log debug message\"\"\"\n        self._update_stats(logging.DEBUG)\n        self._log_async(logging.DEBUG, message, *args, **kwargs)\n    \n    def info(self, message: str, *args, **kwargs):\n        \"\"\"Log info message\"\"\"\n        self._update_stats(logging.INFO)\n        self._log_async(logging.INFO, message, *args, **kwargs)\n    \n    def warning(self, message: str, *args, **kwargs):\n        \"\"\"Log warning message\"\"\"\n        self._update_stats(logging.WARNING)\n        self._log_async(logging.WARNING, message, *args, **kwargs)\n    \n    def error(self, message: str, *args, **kwargs):\n        \"\"\"Log error message\"\"\"\n        self._update_stats(logging.ERROR)\n        \n        # Add stack trace for errors\n        if 'exc_info' not in kwargs:\n            kwargs['exc_info'] = False\n        \n        # Include current stack trace in debug mode\n        if self.log_level <= logging.DEBUG:\n            stack_trace = '\\n'.join(traceback.format_stack()[:-1])\n            message = f\"{message}\\nStack trace:\\n{stack_trace}\"\n        \n        self._log_async(logging.ERROR, message, *args, **kwargs)\n    \n    def critical(self, message: str, *args, **kwargs):\n        \"\"\"Log critical message\"\"\"\n        self._update_stats(logging.CRITICAL)\n        self._log_async(logging.CRITICAL, message, *args, **kwargs)\n    \n    def exception(self, message: str, *args, **kwargs):\n        \"\"\"Log exception with traceback\"\"\"\n        kwargs['exc_info'] = True\n        self.error(message, *args, **kwargs)\n    \n    def log_performance(self, operation: str, duration: float, success: bool = True, **metadata):\n        \"\"\"Log performance metrics\"\"\"\n        perf_data = {\n            'operation': operation,\n            'duration_ms': round(duration * 1000, 2),\n            'success': success,\n            'timestamp': datetime.now().isoformat(),\n            **metadata\n        }\n        \n        level = logging.INFO if success else logging.WARNING\n        message = f\"Performance: {operation} completed in {perf_data['duration_ms']}ms (success={success})\"\n        \n        # Add metadata to message\n        if metadata:\n            message += f\" - {json.dumps(metadata)}\"\n        \n        self._log_async(level, message)\n    \n    def log_security_event(self, event_type: str, details: Dict[str, Any], severity: str = \"INFO\"):\n        \"\"\"Log security-related events\"\"\"\n        security_data = {\n            'event_type': event_type,\n            'severity': severity,\n            'timestamp': datetime.now().isoformat(),\n            'details': details\n        }\n        \n        level_map = {\n            'DEBUG': logging.DEBUG,\n            'INFO': logging.INFO,\n            'WARNING': logging.WARNING,\n            'ERROR': logging.ERROR,\n            'CRITICAL': logging.CRITICAL\n        }\n        \n        level = level_map.get(severity, logging.INFO)\n        message = f\"Security Event: {event_type} - {json.dumps(security_data)}\"\n        \n        self._log_async(level, message)\n    \n    def set_level(self, level: str):\n        \"\"\"Set logging level\"\"\"\n        level_map = {\n            'DEBUG': logging.DEBUG,\n            'INFO': logging.INFO,\n            'WARNING': logging.WARNING,\n            'ERROR': logging.ERROR,\n            'CRITICAL': logging.CRITICAL\n        }\n        \n        if level in level_map:\n            self.log_level = level_map[level]\n            self.logger.setLevel(self.log_level)\n            \n            # Update console handler level\n            for handler in self.logger.handlers:\n                if isinstance(handler, logging.StreamHandler) and handler.stream == sys.stdout:\n                    handler.setLevel(self.log_level)\n            \n            self.info(f\"Log level set to {level}\")\n        else:\n            self.warning(f\"Invalid log level: {level}\")\n    \n    def get_recent_logs(self, level: str = \"INFO\", limit: int = 100) -> List[str]:\n        \"\"\"Get recent log entries from memory\"\"\"\n        level_map = {\n            'DEBUG': logging.DEBUG,\n            'INFO': logging.INFO,\n            'WARNING': logging.WARNING,\n            'ERROR': logging.ERROR,\n            'CRITICAL': logging.CRITICAL\n        }\n        \n        min_level = level_map.get(level, logging.INFO)\n        \n        with self.memory_lock:\n            filtered_logs = [\n                log for log in self.memory_logs \n                if log.get('level', logging.INFO) >= min_level\n            ]\n            \n            # Sort by timestamp and get most recent\n            filtered_logs.sort(key=lambda x: x.get('timestamp', ''), reverse=True)\n            \n            # Format for display\n            formatted_logs = []\n            for log in filtered_logs[:limit]:\n                formatted_logs.append(log.get('formatted', str(log)))\n            \n            return formatted_logs\n    \n    def clear_logs(self):\n        \"\"\"Clear log files and memory logs\"\"\"\n        # Clear memory logs\n        with self.memory_lock:\n            self.memory_logs.clear()\n        \n        # Clear file logs\n        try:\n            # Close file handlers temporarily\n            handlers_to_remove = []\n            for handler in self.logger.handlers:\n                if isinstance(handler, (logging.FileHandler, logging.handlers.RotatingFileHandler)):\n                    handlers_to_remove.append(handler)\n            \n            for handler in handlers_to_remove:\n                handler.close()\n                self.logger.removeHandler(handler)\n            \n            # Remove log files\n            for log_file in [self.log_file, self.error_log_file]:\n                if os.path.exists(log_file):\n                    os.remove(log_file)\n                \n                # Remove rotated log files\n                for i in range(1, self.max_log_files + 1):\n                    rotated_file = f\"{log_file}.{i}\"\n                    if os.path.exists(rotated_file):\n                        os.remove(rotated_file)\n            \n            # Recreate handlers\n            self._setup_logging()\n            \n            self.info(\"Log files cleared\")\n            \n        except Exception as e:\n            self.error(f\"Error clearing log files: {e}\")\n    \n    def export_logs(self, output_file: str, level: str = \"INFO\", hours: int = 24):\n        \"\"\"Export logs to file\"\"\"\n        try:\n            level_map = {\n                'DEBUG': logging.DEBUG,\n                'INFO': logging.INFO,\n                'WARNING': logging.WARNING,\n                'ERROR': logging.ERROR,\n                'CRITICAL': logging.CRITICAL\n            }\n            \n            min_level = level_map.get(level, logging.INFO)\n            cutoff_time = datetime.now() - timedelta(hours=hours)\n            \n            exported_logs = []\n            \n            # Export from memory logs first\n            with self.memory_lock:\n                for log in self.memory_logs:\n                    if (log.get('level', logging.INFO) >= min_level and\n                        log.get('timestamp_obj', datetime.now()) > cutoff_time):\n                        exported_logs.append(log.get('formatted', str(log)))\n            \n            # Read from log files if needed\n            try:\n                with open(self.log_file, 'r', encoding='utf-8') as f:\n                    for line in f:\n                        if line.strip():\n                            exported_logs.append(line.strip())\n            except (FileNotFoundError, PermissionError):\n                pass\n            \n            # Write to output file\n            with open(output_file, 'w', encoding='utf-8') as f:\n                f.write(f\"DexAgents Log Export\\n\")\n                f.write(f\"Generated: {datetime.now().isoformat()}\\n\")\n                f.write(f\"Level: {level}\\n\")\n                f.write(f\"Hours: {hours}\\n\")\n                f.write(\"-\" * 80 + \"\\n\\n\")\n                \n                for log in exported_logs:\n                    f.write(log + \"\\n\")\n            \n            self.info(f\"Logs exported to {output_file} ({len(exported_logs)} entries)\")\n            \n        except Exception as e:\n            self.error(f\"Error exporting logs: {e}\")\n            raise\n    \n    def get_log_stats(self) -> Dict[str, Any]:\n        \"\"\"Get logging statistics\"\"\"\n        runtime = datetime.now() - self.log_stats['start_time']\n        \n        stats = self.log_stats.copy()\n        stats['runtime_seconds'] = runtime.total_seconds()\n        stats['logs_per_minute'] = (stats['total_logs'] / (runtime.total_seconds() / 60)) if runtime.total_seconds() > 0 else 0\n        stats['memory_logs_count'] = len(self.memory_logs)\n        stats['queue_size'] = self.log_queue.qsize()\n        stats['queue_running'] = self.queue_running\n        \n        return stats\n    \n    def cleanup(self):\n        \"\"\"Cleanup logger resources\"\"\"\n        self.info(\"Logger cleanup started\")\n        \n        # Stop queue processor\n        self._stop_queue_processor()\n        \n        # Close all handlers\n        for handler in self.logger.handlers:\n            try:\n                handler.close()\n            except Exception as e:\n                print(f\"Error closing handler: {e}\", file=sys.stderr)\n        \n        self.logger.handlers.clear()\n        \n        # Clear memory logs\n        with self.memory_lock:\n            self.memory_logs.clear()\n\nclass MemoryHandler(logging.Handler):\n    \"\"\"Custom handler to store logs in memory for GUI display\"\"\"\n    \n    def __init__(self, logger_instance):\n        super().__init__()\n        self.logger_instance = logger_instance\n    \n    def emit(self, record):\n        try:\n            formatted = self.format(record)\n            \n            log_entry = {\n                'level': record.levelno,\n                'level_name': record.levelname,\n                'message': record.getMessage(),\n                'timestamp': datetime.fromtimestamp(record.created).isoformat(),\n                'timestamp_obj': datetime.fromtimestamp(record.created),\n                'filename': record.filename,\n                'lineno': record.lineno,\n                'funcName': record.funcName,\n                'formatted': formatted\n            }\n            \n            with self.logger_instance.memory_lock:\n                self.logger_instance.memory_logs.append(log_entry)\n                \n                # Limit memory usage\n                if len(self.logger_instance.memory_logs) > self.logger_instance.max_memory_logs:\n                    self.logger_instance.memory_logs.pop(0)\n                    \n        except Exception:\n            self.handleError(record)\n\ndef main():\n    \"\"\"Test logger functionality\"\"\"\n    logger = Logger(\"TestLogger\", \"test_logs\")\n    \n    # Test various log levels\n    logger.debug(\"This is a debug message\")\n    logger.info(\"This is an info message\")\n    logger.warning(\"This is a warning message\")\n    logger.error(\"This is an error message\")\n    logger.critical(\"This is a critical message\")\n    \n    # Test performance logging\n    start_time = time.time()\n    time.sleep(0.1)\n    logger.log_performance(\"test_operation\", time.time() - start_time, success=True, param1=\"value1\")\n    \n    # Test security logging\n    logger.log_security_event(\"login_attempt\", {\n        \"username\": \"test_user\",\n        \"ip_address\": \"192.168.1.100\",\n        \"success\": True\n    }, \"INFO\")\n    \n    # Test exception logging\n    try:\n        raise ValueError(\"Test exception\")\n    except Exception:\n        logger.exception(\"Test exception occurred\")\n    \n    # Show stats\n    print(\"\\n=== Log Stats ===\")\n    stats = logger.get_log_stats()\n    print(json.dumps(stats, indent=2, default=str))\n    \n    # Show recent logs\n    print(\"\\n=== Recent Logs ===\")\n    recent_logs = logger.get_recent_logs(level=\"DEBUG\", limit=10)\n    for log in recent_logs:\n        print(log)\n    \n    # Cleanup\n    logger.cleanup()\n    \n    # Clean up test directory\n    import shutil\n    try:\n        shutil.rmtree(\"test_logs\")\n    except Exception:\n        pass\n\nif __name__ == \"__main__\":\n    main()"}